{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dr. Semmelweis and the Discovery of Handwashing',\n",
       " 'Exploring the Evolution of Linux',\n",
       " 'Up and Down With the Kardashians']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exploratory code for the page\n",
    "#Define the Python project page and parse the soup\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "page = requests.get('https://www.datacamp.com/projects/tech:python/from_search:true')\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "\n",
    "#Finding all of the links on the page\n",
    "proj_href = []\n",
    "for a in soup.find_all('a', href=True):\n",
    "    proj_href.append(a['href'])\n",
    "#Filtering for just the url tails that lead to projects\n",
    "proj_href_filter = [k for k in proj_href if '/projects/' in k]\n",
    "proj_url_list = [i for i in proj_href_filter if 'topic' not in i]\n",
    "\n",
    "\n",
    "#Finding all of the associated Python project titles\n",
    "proj_title_list = []\n",
    "filt = 'dc-project-block__title'\n",
    "for b in soup.find_all('h5', filt):    \n",
    "    proj_title_list.append(b.get_text())\n",
    "\n",
    "    \n",
    "#Create a dataframe that associates project title with sub url and adds the base url from the website\n",
    "import pandas as pd\n",
    "projects = pd.DataFrame({'proj_title':proj_title_list, 'proj_url':proj_url_list})\n",
    "base_url = 'https://www.datacamp.com'\n",
    "projects['proj_url'] = base_url + projects['proj_url']\n",
    "\n",
    "\n",
    "#Create a dictionary of courses for each project...page and soup are redefined inside the loop here\n",
    "proj_url = projects['proj_url']\n",
    "proj_title = projects['proj_title']\n",
    "proj_dict = {}\n",
    "\n",
    "for p in proj_url:\n",
    "    reqs_list = []\n",
    "    page2 = requests.get(p)                                  #requests page information for the keys\n",
    "    soup2 = BeautifulSoup(page2.content, 'html.parser')      #parses the page for content\n",
    "    for a in soup2.find_all('a', href=True):                 #creates a list of all hyperlinks on page\n",
    "        reqs_list.append(a['href'])\n",
    "    reqs_list = [r for r in reqs_list if '/courses/' in r]   #filters for hyperlinks that are courses\n",
    "    reqs_list = [s[33:] for s in reqs_list]                  #removes the html tag data from the hyperlink\n",
    "    reqs_list = [t.replace('-', ' ') for t in reqs_list]     #takes our url '-' to make prereqs human readable\n",
    "    proj_dict.update({p:reqs_list})                          #creates key/value for dictionary\n",
    "    \n",
    "    \n",
    "#Rename keys from project urls to the project titles\n",
    "proj_dict = dict(zip(proj_title, proj_dict.values()))\n",
    "\n",
    "\n",
    "#list of completed DataCamp Courses (customize to your status) (maybe automate soon?)\n",
    "completed_course = ['introduction to python',\n",
    "                    'intermediate python for data science',\n",
    "                    'python data science toolbox part 1',\n",
    "                    'python data science toolbox part 2',\n",
    "                    'pandas foundations',\n",
    "                    'importing data in python part 1',\n",
    "                    'importing data in python part 2',\n",
    "                    'cleaning data in python']\n",
    "#list of completed DataCamp Projects (customize to your status) (maybe automate soon?)\n",
    "completed_project = ['Introduction to DataCamp Projects',\n",
    "                     'Generating Keywords for Google Ads',\n",
    "                     'TV, Halftime Shows, and the Big Game']\n",
    "\n",
    "\n",
    "#filter for project titles based on all prereqs existing in completed course list\n",
    "qualified_project = []\n",
    "for key in proj_dict:\n",
    "    result = all(elem in completed_course for elem in proj_dict[key])  #filter keys that have all completed values\n",
    "    if result is True:   \n",
    "        qualified_project.append(key)\n",
    "qualified_project\n",
    "\n",
    "\n",
    "#remove completed projects\n",
    "available_project = [proj for proj in qualified_project if proj not in completed_project]\n",
    "available_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
